# -*- coding: utf-8 -*-
"""VGG19_BT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UyhC41remWqRm9-YzbTxdtSkGuaBXWPC

# VGG19
VGG19 is a convolutional neural network (CNN) architecture that wIt is a deep neural network architecture known for its simplicity and effectiveness in image classification tasks. VGG19 is an extension of the original VGG16 architecture, with 19 layersas developed by the Visual Geometry Group (VGG).VGG19 typically takes color images as input, with a fixed size of 224x224 pixels.VGG19 consists of 16 convolutional layers, each followed by a Rectified Linear Unit (ReLU) activation function.The convolutional layers use small 3x3 filters, with a stride of 1 pixel.  
  After every two convolutional layers, VGG19 includes a max-pooling layer with a 2x2 window and a stride of 2x2.There are three fully connected layers.The first two fully connected layers consist of 4,096 neurons each and use ReLU activation.The third fully connected layer has 1,000 neurons (for ImageNet classification) and uses a softmax activation function to produce class probabilities.VGG19 is a computationally intensive model with a large number of parameters.

Install Kaagle Library
"""

pip install kaggle

"""Uploading kaagle API key to download Dataset"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

!mkdir -p /root/.kaggle
!mv kaggle.json /root/.kaggle/

!chmod 600 /root/.kaggle/kaggle.json

"""Downloading Dataset"""

!kaggle datasets download -d navoneel/brain-mri-images-for-brain-tumor-detection

import tensorflow as tf
from zipfile import ZipFile
import os,glob
import cv2
from tqdm._tqdm_notebook import tqdm_notebook as tqdm
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D
from keras.layers import BatchNormalization
from keras.layers import MaxPooling2D
from keras.layers import Flatten

"""Extracting the Data From ZipFile"""

from zipfile import ZipFile
file_name = "/content/brain-mri-images-for-brain-tumor-detection.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')

os.chdir('/content/brain_tumor_dataset/yes')
X = []
y = []
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(224,224))
      X.append(img)
      y.append((i[0:1]))
      print(i[0:1])
os.chdir('/content/brain_tumor_dataset/no')
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(224,224))
      X.append(img)
for i in range(1,99):
    y.append('N')
print(y)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(X[i], cmap="gray")
    plt.axis('off')
plt.show()

"""DataSet Splitting"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
print ("Shape of an image in X_train: ", X_train[0].shape)
print ("Shape of an image in X_test: ", X_test[0].shape)

le = preprocessing.LabelEncoder()
y_train = le.fit_transform(y_train)
y_test = le.fit_transform(y_test)
y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)
y_train = np.array(y_train)
X_train = np.array(X_train)
y_test = np.array(y_test)
X_test = np.array(X_test)

print("X_train Shape: ", X_train.shape)
print("X_test Shape: ", X_test.shape)
print("y_train Shape: ", y_train.shape)
print("y_test Shape: ", y_test.shape)

"""Import VGG19"""

from keras.applications import vgg19


img_rows, img_cols = 224, 224


vgg = vgg19.VGG19(weights = 'imagenet',
                 include_top = False,
                 input_shape = (img_rows, img_cols, 3))

# Here we freeze the last 4 layers
# Layers are set to trainable as True by default
for layer in vgg.layers:
    layer.trainable = False

# Let's print our layers
for (i,layer) in enumerate(vgg.layers):
    print(str(i) + " "+ layer.__class__.__name__, layer.trainable)

def lw(bottom_model, num_classes):
    """creates the top or head of the model that will be
    placed ontop of the bottom layers"""

    top_model = bottom_model.output
    top_model = GlobalAveragePooling2D()(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(512,activation='relu')(top_model)
    top_model = Dense(num_classes,activation='softmax')(top_model)
    return top_model

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D

from keras.models import Model


num_classes = 2

FC_Head = lw(vgg, num_classes)

model = Model(inputs = vgg.input, outputs = FC_Head)

print(model.summary())

"""Training"""

from tensorflow.keras.models import Model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])

history = model.fit(X_train,y_train,
                    epochs=20,
                    validation_data=(X_test,y_test),
                    verbose = 1,
                    initial_epoch=0)

"""Testing"""

from keras.preprocessing import image
import matplotlib.pyplot as plt

# Load and preprocess the test image
test_image_path = "/content/brain_tumor_dataset/no/11 no.jpg"  # Replace with the path to your test image
test_image = cv2.imread(test_image_path)
test_image = cv2.resize(test_image, (224, 224))
test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension
test_image = test_image / 255.0  # Normalize pixel values (assuming VGG16 preprocessing)

# Make predictions
predictions = model.predict(test_image)

# Interpret the prediction result
if predictions[0][0] < predictions[0][1]:
    prediction_label = "No"
else:
    prediction_label = "Yes"

# Display the test image along with the predicted label
plt.imshow(cv2.cvtColor(cv2.imread(test_image_path), cv2.COLOR_BGR2RGB))
plt.title(f"Prediction: {prediction_label}")
plt.axis('off')
plt.show()

from keras.preprocessing import image
import matplotlib.pyplot as plt

# Load and preprocess the test image
test_image_path = "/content/yes/Y102.jpg"  # Replace with the path to your test image
test_image = cv2.imread(test_image_path)
test_image = cv2.resize(test_image, (224, 224))
test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension
test_image = test_image / 255.0  # Normalize pixel values (assuming VGG16 preprocessing)

# Make predictions
predictions = model.predict(test_image)

# Interpret the prediction result
if predictions[0][0] > predictions[0][1]:
    prediction_label = "No"
else:
    prediction_label = "Yes"

# Display the test image along with the predicted label
plt.imshow(cv2.cvtColor(cv2.imread(test_image_path), cv2.COLOR_BGR2RGB))
plt.title(f"Prediction: {prediction_label}")
plt.axis('off')
plt.show()